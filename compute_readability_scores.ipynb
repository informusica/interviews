{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### Install nltk_contrib\n",
    "<code>\n",
    "$ git clone https://github.com/nltk/nltk_contrib.git\n",
    "$ cd nltk_contrib\n",
    "$ python setup.py install\n",
    "</code>\n",
    "\n",
    "Also ensure you have the <code>Punkt</code> tokenizer installed through nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and export readability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk_contrib.readability.readabilitytests import ReadabilityTool\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# suppress the warnings logged by ReadabilityTool()\n",
    "import logging\n",
    "logging.getLogger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_readability_scores(path_to_transcription_file):\n",
    "    transcriptions = pickle.load(open(path_to_transcription_file, 'rb'))\n",
    "    \n",
    "    score_dictionary = {}\n",
    "    \n",
    "    for video_id in transcriptions:\n",
    "        transcription = transcriptions[video_id]\n",
    "        # if video filename starts with '-', have it start with '?-'\n",
    "        if video_id[0] == '-':\n",
    "            video_id = '?%s' % video_id\n",
    "    \n",
    "        current_video_scores = {}\n",
    "        current_video_scores['video_id'] = video_id\n",
    "        \n",
    "        if len(transcription) > 0:\n",
    "            transcription_readability_tool = ReadabilityTool(transcription)\n",
    "\n",
    "            current_video_scores['ARI'] = transcription_readability_tool.ARI()\n",
    "            current_video_scores['Flesch Reading Ease'] = \\\n",
    "                transcription_readability_tool.FleschReadingEase()\n",
    "            current_video_scores['Flesch-Kincaid Grade Level'] = \\\n",
    "                transcription_readability_tool.FleschKincaidGradeLevel()\n",
    "            current_video_scores['Gunning Fog Index'] = \\\n",
    "                transcription_readability_tool.GunningFogIndex()\n",
    "            current_video_scores['SMOG Index'] = \\\n",
    "                transcription_readability_tool.SMOGIndex()\n",
    "            current_video_scores['Coleman Liau Index'] = \\\n",
    "                transcription_readability_tool.ColemanLiauIndex()\n",
    "            current_video_scores['LIX'] = transcription_readability_tool.LIX()\n",
    "            current_video_scores['RIX'] = transcription_readability_tool.RIX()\n",
    "        else:\n",
    "            print 'Video without transcription?? Check video %s' % video_id\n",
    "            # set all scores to NaN\n",
    "            current_video_scores['ARI'] = float('nan')\n",
    "            current_video_scores['Flesch Reading Ease'] = float('nan')\n",
    "            current_video_scores['Flesch-Kincaid Grade Level'] = float('nan')\n",
    "            current_video_scores['Gunning Fog Index'] = float('nan')\n",
    "            current_video_scores['SMOG Index'] = float('nan')\n",
    "            current_video_scores['Coleman Liau Index'] = float('nan')\n",
    "            current_video_scores['LIX'] = float('nan')\n",
    "            current_video_scores['RIX'] = float('nan')\n",
    "            \n",
    "        \n",
    "        score_dictionary[video_id] = current_video_scores \n",
    "        \n",
    "    return score_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "readability_scores = get_readability_scores('/Volumes/Samsung_T3/ChaLearn/val/transcription_validation.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def export_scores_to_csv(score_dictionary, path_to_csv):\n",
    "    writer = csv.DictWriter(open(path_to_csv, 'w'),\\\n",
    "                            delimiter=',',\\\n",
    "                            fieldnames=['video_id',\n",
    "                                        'ARI',\\\n",
    "                                        'Flesch Reading Ease',\\\n",
    "                                        'Flesch-Kincaid Grade Level',\\\n",
    "                                        'Gunning Fog Index',\\\n",
    "                                        'SMOG Index',\\\n",
    "                                        'Coleman Liau Index',\\\n",
    "                                        'LIX',\\\n",
    "                                        'RIX'\n",
    "                                       ])\n",
    "    \n",
    "    writer.writeheader()\n",
    "    \n",
    "    for video_id in score_dictionary:\n",
    "        writer.writerow(score_dictionary[video_id])\n",
    "\n",
    "    return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_scores_to_csv(readability_scores, '/Volumes/Samsung_T3/ChaLearn/test/scores_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET CORRECTIONS\n",
    "### Training transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transcription_training = pickle.load(open('/YOUR/PATH/TO/transcription_training.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transcription_training['iYVJt41_q7M.002.mp4'] = u'all set, ok? Thank you for showing so much love across this channel. Hundred subscribers soon, I cannot wait for that, I\\'ll give away when that happens as well. Just thank you so much generally from the bottom of my heart for the love you\\'re showing on this channel. You guys take care and I will see you in the next video.' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transcription_training['4LZJvOecyM8.005.mp4'] = u'-ly. Uhh, dududududududu - Interview With The Vampire, Queen of the Damned, tsk tsk tsk tsk tsk tsk tsk uhh uhm ... that\\'s all I\\'m gonna leave for right now, we\\'ll see like the big main ones. Uhh...what did it take you to-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transcription_training['YC3X1DcnUrk.000.mp4'] = u'but especially probably Princess Mononoke is just... the most beautiful, uhh, movie, uhh, it\\'s, yeah, it\\'s just one of our favorite films in all categories, not just in the \"Animated\" sort of category. Uhmm...other Japanese animated films that we love-' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transcription_training['ztyBhnjtrz0.000.mp4'] = u'like model curves. Hayo Smith asked: \"Why are you so generous?\". Well, I like to give things away, and it\\'s a nice thing to do. Even though I don\\'t have a lot of money, but I have enough money to-' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transcription_training['JTmq4k4uQCY.003.mp4'] = u'build buildings, and you play, and fun, and the...the regular blocks are the best ones, \\'cause you can build anything with them. Everyone knows all that about Lego already, and...Minecraft is that, but you get to actually move around and play in this 3D world. I wouldn\\'t, like, throw them into survival mode, but I\\'d-' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transcription_training['HhC2cGFFZeY.000.mp4'] = u'being 200 pounds would look monstrous, like, literally, what, uhmm, if you look at Lex Griffen, I think he\\'s got similar build to me, like, bone density-wise, and, I think he is about similar height, and, he looks huge and he is only 170 pounds. I\\'m about-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transcription_training['cRDYrvxRJ6U.001.mp4'] = u'then, what relationships they wanna have, they get really clear and really focused, they live a life that\\'s very purposeful to them. I absolutely love giving this to my clients. It\\'s so, so, so much fun. So that\\'s kinda what you can expect, working with a light coach especially'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(transcription_training, open('/YOUR/PATH/TO/transcription_training_extended.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transcription_test = pickle.load(open('/YOUR/PATH/TO/ChaLearn/test/transcription_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transcription_test['JmAQlC-FEV8.000.mp4'] = u'pre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transcription_test['_plk5k7PBEg.004.mp4'] = u'stuff I know, and a video, uhmm, two videos ago, whatever it was, where I talked about being a normal tech YouTube person enough anymore. I wanna make some things clear: I\\'m not saying I\\'m stopping all kinds of technology videos. I\\'ll still do videos related to technology, and I will still do' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(transcription_test, open('/YOUR/PATH/TO/transcription_test_extended.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
